{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import the data and the packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_personal_example'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l8/p0_hwx4d2hvbqs4crpsfjlzc0000gn/T/ipykernel_3476/3673841486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinomtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_personal_example\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransaction_data_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_data_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlarge_pre_gas_prices_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuite_spot_txn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuite_spot_blx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_post_eip_txn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnew_post_eip_blx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_post_eip_rcpts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_personal_example'"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "from data_personal_example import transaction_data_file, block_data_file,  \\\n",
    "large_pre_gas_prices_file, suite_spot_txn, suite_spot_blx, new_post_eip_txn, \\\n",
    "new_post_eip_blx, new_post_eip_rcpts\n",
    "\n",
    "\n",
    "#Read in the data, use your own machines specific path as you see fit\n",
    "post_transaction_data=pd.read_csv(transaction_data_file)\n",
    "post_block_data=pd.read_csv(block_data_file)\n",
    "#read in the data and convert it to a list for better calculation speed\n",
    "large_pre_gas_prices=list(pd.read_csv(large_pre_gas_prices_file).gas_price)\n",
    "#read in sweet spot data\n",
    "suite_txn=pd.read_csv(suite_spot_txn)\n",
    "suite_blx=pd.read_csv(suite_spot_blx)\n",
    "\n",
    "\n",
    "##can be disregarded, basically a failed experiment\n",
    "#read in the spike free data\n",
    "new_txn=pd.read_csv(new_post_eip_txn)\n",
    "new_blx=pd.read_csv(new_post_eip_blx)\n",
    "new_rpcts=pd.read_csv(new_post_eip_rcpts)\n",
    "thing=pd.read_csv(large_pre_gas_prices_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adding the gas limits into the dataframe*\n",
    "\n",
    "first we add the gas limits into the transaction dataframe, as well as add the gas limits and base fee back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the block number and gas limits and base fee from the dataset\n",
    "post_block_number=list(post_block_data.block_number)\n",
    "post_gas_limit=list(post_block_data.gas_limit)\n",
    "post_base_fee=list(post_block_data.base_fee_per_gas)\n",
    "#initialize a dictionary to assign gas limits and base fee to the transaction data\n",
    "gas_limit_tracker={}\n",
    "base_fee_tracker={}\n",
    "\n",
    "\n",
    "#makes a dicionary with the key being the block number and the \n",
    "#value being the gas limits and base fee, because this will allow us to \n",
    "#easily assign a gas limit and base fee to the transaction going forward\n",
    "for i in range(len(post_block_number)):\n",
    "    gas_limit_tracker[post_block_number[i]]=post_gas_limit[i]\n",
    "    base_fee_tracker[post_block_number[i]]=post_base_fee[i]\n",
    "    \n",
    "    \n",
    "##get the block numbers from the transaction data\n",
    "post_transaction_block_numbers=list(post_transaction_data.block_number)\n",
    "\n",
    "\n",
    "#initialize a list for the purpose of saving the gas limits that will \n",
    "#be assigned to the transaction data and assign the correct information\n",
    "gas_limits_for_transaction_data=[gas_limit_tracker[x] for x in post_transaction_block_numbers]\n",
    "base_fee_for_transaction_data=[base_fee_tracker[x] for x in post_transaction_block_numbers]\n",
    "\n",
    "    \n",
    "#add the column into the dataframe\n",
    "#transaction_data['gas_limit']=gas_limits_for_transaction_data\n",
    "post_transaction_data['base_fee']=base_fee_for_transaction_data\n",
    "\n",
    "\n",
    "# The final step is to remove the NA's from then dataframe, from testing of the \n",
    "# dataset, i have found that the max priority fee per gas and the max fee per gas\n",
    "# have the the same number of NA's -this can be oberved with the line \n",
    "# np.sum(transaction_data.isna())- that we can remove the NA's with the line...\n",
    "post_transaction_data= \\\n",
    "post_transaction_data[pd.notnull(post_transaction_data.max_fee_per_gas)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Rescaling the gas prices*\n",
    "\n",
    " now we need to add another column to revert the gas price into a metric that we \n",
    "can compare to the pre EIP 1559 data. to do this, we will need to work under the\n",
    " assumption that gas limits represent the same metric that they do in the pre EIP \n",
    " 1559 network (which is an assumption that the previous paper made that we will \n",
    " continue in this proposal). then, we see that the user bid has a specific value \n",
    " in the post EIP 1559 section which is min(base fee + tip , max tip), while in the pre EIP section the userbid is equal \n",
    " to gas price * gas limit. Therefore, if we set these metrics to be equal, we can \n",
    " solve for the equivilent of the gas prices in the post EIP section, giving us an ultimate answer of $\\frac{min(base \\: fee \\: + \\: tip, \\:  max \\: fee)}{gas \\: limit}  \\: =equivilent \\: to \\: pre \\: EIP \\: gas \\: price$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the values...\n",
    "b_fee=list(post_transaction_data.base_fee)\n",
    "g_limit=list(post_transaction_data.gas)\n",
    "m_fee=list(post_transaction_data.max_fee_per_gas)\n",
    "tip=list(post_transaction_data.max_priority_fee_per_gas)\n",
    "\n",
    "\n",
    "#Evaluate and store the rescaled gas prices\n",
    "rescaled_gas_prices=[min(b_fee[x]+tip[x],m_fee[x])/g_limit[x] for \\\n",
    "                    x in range(len(b_fee))]\n",
    "\n",
    "#transaction_data=transaction_data['rescaled_gas_prices']=rescaled_gas_prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comparing variance*\n",
    "\n",
    "We will be comparing the variance in two ways, first, we will be simply taking the variance of the entire dataset, then we will run a simulation where the code will randomly take sets of 500 from both the pre and post EIP 1559 data and compare the variance in a simulation of many times and reports the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Clean up the data for comparison, remove outliers*\n",
    "\n",
    "I will be using the \"03_22_03_26.csv\" dataset in the CAMCOS google drive for the largest portion of data available, for both the 03_22_03_26.csv dataset and the suite spot dataset I'm going to use 40,000 results for a more appropriate comparison of variance.\n",
    "\n",
    "*First we will clean up the pre EIP dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly generate 40000 indexes for the larger dataset\n",
    "pre_index=np.random.uniform(0,len(large_pre_gas_prices)-2,40000)\n",
    "pre_index=[round(x) for x in pre_index]\n",
    "\n",
    "\n",
    "#assign values with the random indexes\n",
    "pre_gas_prices=[large_pre_gas_prices[x] for x in pre_index]\n",
    "    \n",
    "\n",
    "#gets 10% quantile and 90% quantile for both pre and post \n",
    "#for later use in removing outliers\n",
    "pre_up_lim=np.quantile(pre_gas_prices,0.9)\n",
    "pre_lo_lim=np.quantile(pre_gas_prices,0.1)\n",
    "post_up_lim=np.quantile(rescaled_gas_prices,0.9)\n",
    "post_lo_lim=np.quantile(rescaled_gas_prices,0.1)\n",
    "\n",
    "\n",
    "#Remove the outliers, save the results in two variables that\n",
    "#will be our final variables\n",
    "pre_gas=[x for x in pre_gas_prices if (x<pre_up_lim) & (x>pre_lo_lim)]\n",
    "post_gas=[x for x in rescaled_gas_prices if (x<post_up_lim) & (x>post_lo_lim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now to clean uo the suite spot data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gas prices\n",
    "suite_gas_prices=list(suite_txn.gas_price)\n",
    "\n",
    "#randomly generate 40000 indexes for the larger dataset\n",
    "suite_index=np.random.uniform(0,len(suite_gas_prices)-2,40000)\n",
    "suite_index=[round(x) for x in suite_index]\n",
    "\n",
    "\n",
    "#assign values with the random indexes\n",
    "suite_gas_prices=[suite_gas_prices[x] for x in suite_index]\n",
    "    \n",
    "\n",
    "#gets 10% quantile and 90% quantile for both suite gas\n",
    "suite_up_lim=np.quantile(suite_gas_prices,0.9)\n",
    "suite_lo_lim=np.quantile(suite_gas_prices,0.1)\n",
    "\n",
    "\n",
    "\n",
    "#Remove the outliers, save the results\n",
    "suite_gas=[x for x in suite_gas_prices if (x<suite_up_lim) & (x>suite_lo_lim)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simulation 1: non-ideal data*\n",
    "\n",
    "This simulation will be done with a normalization method, where for each unit i in n we take $\\frac{n_i}{(n_i)^2}$ to try to account for the discrepency of the size of the units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a function to normalize the gas price data via dividing by the square of the mean\n",
    "def my_normalizer(my_list):\n",
    "    \n",
    "#    my_mean=np.mean(my_list)**2\n",
    "    return [x/(x**2) for x in my_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#a function designed to take two lists, pre and post EIP respectively,\n",
    "#and return False if post is bigger and True if post is smaller\n",
    "def variance_checker(pre,post):\n",
    "    if np.var(pre)<np.var(post):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "#a function desinged to take two lists, along with a specefied integer, and then\n",
    "#generate an amount of random indexes associated with indexes to the two lists \n",
    "#in the amount of the number specified\n",
    "def random_index_generator(list1,list2,number):\n",
    "    result1=list(np.random.uniform(0,len(list1)-2,number))\n",
    "    result1=[round(x) for x in result1]\n",
    "    result2=list(np.random.uniform(0,len(list2)-2,number))\n",
    "    result2=[round(x) for x in result2]\n",
    "    return [result1,result2]\n",
    "\n",
    "\n",
    "#declare a variable to represent the number of trials to take place in the simulation \n",
    "trials=10000\n",
    "#initialize a list to represent the output of the simulation\n",
    "results=[]\n",
    "\n",
    "\n",
    "#this code runs a simulation that randomly takes 500 observations from each dataset and \n",
    "#records the percentage of times the variance is smaller in the post EIP dataset\n",
    "for i in range(trials):\n",
    "    my_index=random_index_generator(pre_gas,post_gas,500)\n",
    "    index_1=my_index[0]\n",
    "    index_2=my_index[1]\n",
    "    my_pre_gas=my_normalizer([pre_gas[x] for x in index_1])\n",
    "    my_post_gas=my_normalizer([post_gas[x] for x in index_2])\n",
    "    results.append(variance_checker(my_pre_gas,my_post_gas))\n",
    "\n",
    "    \n",
    "#output results of simulation and simple variance of the two datasets\n",
    "print(\"the variance in the post EIP-1559 data is \" +  str(np.var(my_normalizer(post_gas))) + \\\n",
    "      \" and the variance in the pre EIP-1559 data is \" + str(np.var(my_normalizer(pre_gas))) + \\\n",
    "      \". the percentage of times the variance was lower in post EIP-1559 data \" + \\\n",
    "      \"durring our simulation after normalizing was \" +\n",
    "      str(int(round((sum(results)/len(results))*100))) + '%. Note, the data had ' + \\\n",
    "      \"to be normalized to make up for the discrepency of size in the units\")\n",
    "\n",
    "\n",
    "#output summary stats of pre and post EIP gas prices\n",
    "print('\\n Some summary stats: \\n \\t Pre-EIP: \\n')\n",
    "print('\\t Max: ' + str(np.max(pre_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(pre_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(pre_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(pre_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(pre_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(pre_gas,0.5)) + ',' +  str(np.quantile(pre_gas,0.75)))\n",
    "print('\\n \\n \\t Post-EIP:')\n",
    "print('\\t Max: ' + str(np.max(post_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(post_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(post_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(post_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(post_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(post_gas,0.5)) + ',' +  str(np.quantile(post_gas,0.75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simulation 2: suite spot data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare a variable to represent the number of trials to take place in the simulation \n",
    "trials=10000\n",
    "#initialize a list to represent the output of the simulation\n",
    "results=[]\n",
    "\n",
    "\n",
    "#this code runs a simulation that randomly takes 500 observations from each dataset and \n",
    "#records the percentage of times the variance is smaller in the post EIP dataset\n",
    "for i in range(trials):\n",
    "    my_index=random_index_generator(suite_gas,post_gas,500)\n",
    "    index_1=my_index[0]\n",
    "    index_2=my_index[1]\n",
    "    my_suite_gas=my_normalizer([suite_gas[x] for x in index_1])\n",
    "    my_post_gas=my_normalizer([post_gas[x] for x in index_2])\n",
    "    results.append(variance_checker(my_suite_gas,my_post_gas))\n",
    "\n",
    "    \n",
    "#output results of simulation and simple variance of the two datasets\n",
    "print(\"the variance in the post EIP-1559 data is \" +  str(np.var(my_normalizer(post_gas))) + \\\n",
    "      \" and the variance in the 'suite spot' EIP-1559 data is \" + str(np.var(my_normalizer(suite_gas))) + \\\n",
    "      \". the percentage of times the variance was lower in post EIP-1559 data \" + \\\n",
    "      \"durring our simulation after normalizing was \" +\n",
    "      str(int(round((sum(results)/len(results))*100))) + '%. Note, the data had ' + \\\n",
    "      \"to be normalized to make up for the discrepency of size in the units\")\n",
    "\n",
    "\n",
    "#output summary stats of pre and post EIP gas prices\n",
    "print('\\n Some summary stats: \\n \\t Pre-EIP: (suite spot) \\n')\n",
    "print('\\t Max: ' + str(np.max(suite_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(suite_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(suite_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(suite_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(suite_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(suite_gas,0.5)) + ',' +  str(np.quantile(suite_gas,0.75)))\n",
    "print('\\n \\n \\t Post-EIP:')\n",
    "print('\\t Max: ' + str(np.max(post_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(post_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(post_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(post_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(post_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(post_gas,0.5)) + ',' +  str(np.quantile(post_gas,0.75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implementation of the c-test*\n",
    "\n",
    "This method works by approximating the joint probability distribution of X_1 and X_2 as a binomial distribution, where in the binomial distibtion, the x parameter is lambda_1 (from X_1), the n parameter is lambda_1+lambda_2, and the p parameter is n_1/(n_1+n_2) This test finds the p-value corresponding to the ratio lambda_1/lambda_2, the reasoning being that if the ratio is large, then that means lambda 1 is larger than lambda 2 (and thus that variance of the pre EIP gas price is larger than the variance of the post EIP gas price) to a statistically significant degree. Hence, we perform a \"greater than\" binomial test to determine of the if the variance is smaller in the post EIP framework.\n",
    "\n",
    "This method was retrieved from the following sources: \n",
    "\n",
    "1. https://stats.stackexchange.com/questions/109402/c-test-for-comparing-poisson-means-in-scipy\n",
    "\n",
    "2. https://cran.r-project.org/web/packages/rateratio.test/vignettes/rateratio.test.pdf\n",
    "\n",
    "*The first implementation will be conducted on the non-ideal data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##grab the parameters for the test\n",
    "my_x=int(np.mean(pre_gas))\n",
    "my_n=int(np.mean(pre_gas))+int(np.mean(post_gas))\n",
    "my_p=len(pre_gas)/(len(pre_gas)+len(post_gas))\n",
    "\n",
    "\n",
    "#print the results of the test to the user\n",
    "print('\\n \\n') \n",
    "print(binomtest((my_x),my_n,my_p,alternative='greater'))\n",
    "print('\\n \\n' + 'This result means that we reject the null hypothesis, meaning that the' + \\\n",
    "      ' variance in the pre EIP framework \\n' + 'is larger than the post EIP to a ' +\\\n",
    "      'statistically significant degree' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The second implimentation of the c-test will be on the ideal data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##grab the parameters for the test\n",
    "my_x=int(np.mean(suite_gas))\n",
    "my_n=int(np.mean(suite_gas))+int(np.mean(post_gas))\n",
    "my_p=len(suite_gas)/(len(suite_gas)+len(post_gas))\n",
    "\n",
    "\n",
    "#print the results of the test to the user\n",
    "print('\\n \\n') \n",
    "print(binomtest((my_x),my_n,my_p,alternative='greater'))\n",
    "print('\\n \\n' + 'This result means that we reject the null hypothesis, meaning that the' + \\\n",
    "      ' variance in the pre EIP framework (suite spot) \\n' + 'is larger than the post EIP to a ' +\\\n",
    "      'statistically significant degree' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better result from the variance checker, we will omit the blocks that are from the spikes. The results seem to indicate that the most severe spikes in the first 8000 observations are from 12965850 - 12966400, 12966100 - 12966650, and 12972200 - 12972600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(new_txn)\n",
    "#display(new_blx)\n",
    "#display(new_rpcts)\n",
    "\n",
    "\n",
    "new_rpcts=new_rpcts.rename(columns={'transaction_hash':'hash'})\n",
    "\n",
    "#display(new_rpcts)\n",
    "#new_txn=\n",
    "new_txn=pd.merge(new_rpcts,new_txn,on='hash')\n",
    "\n",
    "\n",
    "\n",
    "#display(new_txn)\n",
    "#display(new_blx)\n",
    "\n",
    "base_fee_tracker={}\n",
    "\n",
    "my_blocks=list(new_blx.number)\n",
    "my_b_fee=list(new_blx.base_fee_per_gas)\n",
    "\n",
    "\n",
    "for i in range(len(my_blocks)):\n",
    "    base_fee_tracker[my_blocks[i]]=my_b_fee[i]\n",
    "    \n",
    "b_fee_for_txn=[]\n",
    "for i in new_txn.block_number:\n",
    "    b_fee_for_txn.append(base_fee_tracker[i])\n",
    "    \n",
    "    \n",
    "new_txn['base_fee_per_gas']=b_fee_for_txn\n",
    "\n",
    "\n",
    "new_txn=new_txn[pd.notnull(new_txn.max_priority_fee_per_gas)]\n",
    "\n",
    "\n",
    "\n",
    "#display(new_txn)\n",
    "\n",
    "#new_txn['valuations']=np.min()\n",
    "\n",
    "my_max_fee=list(new_txn.max_fee_per_gas)\n",
    "my_tip=list(new_txn.max_priority_fee_per_gas)\n",
    "my_b_fee=list(new_txn.base_fee_per_gas)\n",
    "my_g_limit=list(new_txn.gas)\n",
    "\n",
    "\n",
    "\n",
    "rescaled_gas_prices=[]\n",
    "\n",
    "#for i in range(len(my_max_fee)):\n",
    "#    rescaled_gas_prices.append(min(my_b_fee[i] + my_tip[i])/my_gas_limit[i])\n",
    "\n",
    "\n",
    "\n",
    "#rescaled_gas_prices=[min(my_b_fee[x] + my_tip[x] , my_max_fee[x]) / my_gas_limit[x] \n",
    "#for x in range(len(my_g_limit))]\n",
    "\n",
    "#rescaled_gas_prices=[min(b_fee[x]+tip[x],m_fee[x])/g_limit[x] for \\\n",
    "#                    x in range(len(b_fee))]\n",
    "\n",
    "for i in range(len(my_max_fee)):\n",
    "    my_min=min(my_b_fee[i] + my_tip[i] , my_max_fee[i])\n",
    "    price=my_min/my_g_limit[i]\n",
    "    rescaled_gas_prices.append(price)\n",
    "    \n",
    "    \n",
    "new_txn['rescaled_gas_prices']=rescaled_gas_prices\n",
    "display(new_txn)\n",
    "#df[pd.notnull(df.column_of_interest)]\n",
    "#rescaled_gas_prices[0:2]\n",
    "#print(len(my_max_fee),len(my_tip),len(my_b_fee),len(my_g_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start: 12965400 <br>\n",
    "spike 1: 12966050:12966400 <br>\n",
    "spike 2: 12971900:12973400 <br>\n",
    "end: 12975400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NOTE:\n",
    "#these two lines need to be run on the first new run of this code \n",
    "#on your machine, after that, comment them out\n",
    "\n",
    "new_txn=new_txn.sort_values(by=['block_number'])\n",
    "new_txn=new_txn.set_index('block_number')\n",
    "\n",
    "\n",
    "r1=new_txn.loc[12965400:12966050]\n",
    "r1=r1.reset_index()\n",
    "r2=new_txn.loc[12966400:12971900]\n",
    "r2=r2.reset_index()\n",
    "r3=new_txn.loc[12973400:12975400]\n",
    "r3=r3.reset_index()\n",
    "\n",
    "#display(r1)\n",
    "#display(r2)\n",
    "#display(r3)\n",
    "\n",
    "r1_m_r2_m_r3=pd.concat([r1,r2,r3],axis=0)\n",
    "#r1_m_r2_m_r3.loc[0].hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to replicate the results of the variance checker ommiting the blocks with spikes. The first thing we need to do is randomly grab 80000 observations from the pre-eip framework and then remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_index_generator_2(my_list,num_of_indexes):\n",
    "    \n",
    "    my_max=len(my_list)-1\n",
    "    result=np.random.uniform(0,my_max,num_of_indexes)\n",
    "    return [round(x) for x in result]\n",
    "\n",
    "len(large_pre_gas_prices)\n",
    "\n",
    "\n",
    "my_indexes=random_index_generator_2(large_pre_gas_prices,80000)\n",
    "\n",
    "pre_eip_observations=[large_pre_gas_prices[x] for x in my_indexes]\n",
    "post_eip_observations=list(r1_m_r2_m_r3.rescaled_gas_prices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##remove outliers\n",
    "pre_up=np.percentile(pre_eip_observations,90)\n",
    "pre_lo=np.percentile(pre_eip_observations,10)\n",
    "true_pre_eip=[x for x in pre_eip_observations if (x < pre_up) & (x > pre_lo)]\n",
    "\n",
    "post_up=np.percentile(post_eip_observations,90)\n",
    "post_lo=np.percentile(post_eip_observations,10)\n",
    "true_post_eip=[x for x in post_eip_observations if (x < post_up) & (x > post_lo)]\n",
    "print(r1_m_r2_m_r3.iloc[0])\n",
    "print(r1_m_r2_m_r3.hash.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will replicate the variance checker code but with the newest and cleanest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare a variable to represent the number of trials to take place in the simulation \n",
    "trials=10000\n",
    "#initialize a list to represent the output of the simulation\n",
    "results=[]\n",
    "\n",
    "\n",
    "##PRE:true_pre_eip\n",
    "##POST:true_post_eip\n",
    "\n",
    "\n",
    "\n",
    "#this code runs a simulation that randomly takes 500 observations from each dataset and \n",
    "#records the percentage of times the variance is smaller in the post EIP dataset\n",
    "for i in range(trials):\n",
    "    my_index=random_index_generator(true_pre_eip,true_post_eip,500)\n",
    "    index_1=my_index[0]\n",
    "    index_2=my_index[1]\n",
    "    my_pre_gas=my_normalizer([true_pre_eip[x] for x in index_1])\n",
    "    my_post_gas=my_normalizer([true_post_eip[x] for x in index_2])\n",
    "    results.append(variance_checker(my_pre_gas,my_post_gas))\n",
    "\n",
    "    \n",
    "#output results of simulation and simple variance of the two datasets\n",
    "print(\"the variance in the post EIP-1559 (no spike) data is \" +  str(np.var(my_normalizer(true_post_eip))) + \\\n",
    "      \" and the variance in the pre EIP-1559 data is \" + str(np.var(my_normalizer(true_pre_eip))) + \\\n",
    "      \". the percentage of times the variance was lower in post EIP-1559 data \" + \\\n",
    "      \"durring our simulation after normalizing was \" +\n",
    "      str(int(round((sum(results)/len(results))*100))) + '%. Note, the data had ' + \\\n",
    "      \"to be normalized to make up for the discrepency of size in the units\")\n",
    "\n",
    "\n",
    "#output summary stats of pre and post EIP gas prices\n",
    "print('\\n Some summary stats: \\n \\t Pre-EIP: \\n')\n",
    "print('\\t Max: ' + str(np.max(true_pre_eip)))\n",
    "print('\\n \\t Min: ' + str(np.min(true_pre_eip)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(true_pre_eip)))\n",
    "print('\\n \\t Variance: ' + str(np.var(true_pre_eip)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(true_pre_eip,0.25)) + \",\" + \\\n",
    "      str(np.quantile(true_pre_eip,0.5)) + ',' +  str(np.quantile(true_pre_eip,0.75)))\n",
    "print('\\n \\n \\t Post-EIP: (no spike)')\n",
    "print('\\t Max: ' + str(np.max(true_post_eip)))\n",
    "print('\\n \\t Min: ' + str(np.min(true_post_eip)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(true_post_eip)))\n",
    "print('\\n \\t Variance: ' + str(np.var(true_post_eip)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(true_post_eip,0.25)) + \",\" + \\\n",
    "      str(np.quantile(true_post_eip,0.5)) + ',' +  str(np.quantile(true_post_eip,0.75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the base fee just to make sure no spikes got in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_base_fee=list(set(list(r1_m_r2_m_r3.base_fee_per_gas)))\n",
    "my_x=list(range(len(my_base_fee)))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "\n",
    "ax.xaxis.label.set_color('white')\n",
    "ax.yaxis.label.set_color('white')\n",
    "ax.tick_params(axis='x', colors='white')\n",
    "ax.tick_params(axis='y',colors='white')\n",
    "ax.title.set_color('white')\n",
    "plt.plot(my_x,my_base_fee)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02cec3100af4f77b0b3609e30c0b642b32ba8aadb84a5b6ce1efd35086210958"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
