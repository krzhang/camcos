{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import the data and the packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "from data_personal_example import transaction_data_file, block_data_file,  \\\n",
    "large_pre_gas_prices_file, suite_spot_txn, suite_spot_blx\n",
    "\n",
    "\n",
    "#Read in the data, use your own machines specific path as you see fit\n",
    "transaction_data=pd.read_csv(transaction_data_file)\n",
    "block_data=pd.read_csv(block_data_file)\n",
    "#read in the data and convert it to a list for better calculation speed\n",
    "large_pre_gas_prices=list(pd.read_csv(large_pre_gas_prices_file).gas_price)\n",
    "\n",
    "suite_txn=pd.read_csv(suite_spot_txn)\n",
    "suite_blx=pd.read_csv(suite_spot_blx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adding the gas limits into the dataframe*\n",
    "\n",
    "first we add the gas limits into the transaction dataframe, as well as add the gas limits and base fee back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the block number and gas limits and base fee from the dataset\n",
    "my_block_number=list(block_data.block_number)\n",
    "my_gas_limit=list(block_data.gas_limit)\n",
    "my_base_fee=list(block_data.base_fee_per_gas)\n",
    "#initialize a dictionary to assign gas limits and base fee to the transaction data\n",
    "gas_limit_tracker={}\n",
    "base_fee_tracker={}\n",
    "\n",
    "\n",
    "#makes a dicionary with the key being the block number and the \n",
    "#value being the gas limits and base fee, because this will allow us to \n",
    "#easily assign a gas limit and base fee to the transaction going forward\n",
    "for i in range(len(my_block_number)):\n",
    "    gas_limit_tracker[my_block_number[i]]=my_gas_limit[i]\n",
    "    base_fee_tracker[my_block_number[i]]=my_base_fee[i]\n",
    "    \n",
    "    \n",
    "##get the block numbers from the transaction data\n",
    "transaction_block_numbers=list(transaction_data.block_number)\n",
    "\n",
    "\n",
    "#initialize a list for the purpose of saving the gas limits that will \n",
    "#be assigned to the transaction data and assign the correct information\n",
    "gas_limits_for_transaction_data=[gas_limit_tracker[x] for x in transaction_block_numbers]\n",
    "base_fee_for_transaction_data=[base_fee_tracker[x] for x in transaction_block_numbers]\n",
    "\n",
    "    \n",
    "#add the column into the dataframe\n",
    "#transaction_data['gas_limit']=gas_limits_for_transaction_data\n",
    "transaction_data['base_fee']=base_fee_for_transaction_data\n",
    "\n",
    "\n",
    "# The final step is to remove the NA's from then dataframe, from testing of the \n",
    "# dataset, i have found that the max priority fee per gas and the max fee per gas\n",
    "# have the the same number of NA's -this can be oberved with the line \n",
    "# np.sum(transaction_data.isna())- that we can remove the NA's with the line...\n",
    "transaction_data=transaction_data[pd.notnull(transaction_data.max_fee_per_gas)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Rescaling the gas prices*\n",
    "\n",
    " now we need to add another column to revert the gas price into a metric that we \n",
    "can compare to the pre EIP 1559 data. to do this, we will need to work under the\n",
    " assumption that gas limits represent the same metric that they do in the pre EIP \n",
    " 1559 network (which is an assumption that the previous paper made that we will \n",
    " continue in this proposal). then, we see that the user bid has a specific value \n",
    " in the post EIP 1559 section which is min(base fee + tip , max tip), while in the pre EIP section the userbid is equal \n",
    " to gas price * gas limit. Therefore, if we set these metrics to be equal, we can \n",
    " solve for the equivilent of the gas prices in the post EIP section, giving us an ultimate answer of $\\frac{min(base \\: fee \\: + \\: tip)}{gas \\: limit}  \\: = \\: pre \\: EIP \\: gas \\: price$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the values...\n",
    "b_fee=list(transaction_data.base_fee)\n",
    "g_limit=list(transaction_data.gas)\n",
    "m_fee=list(transaction_data.max_fee_per_gas)\n",
    "tip=list(transaction_data.max_priority_fee_per_gas)\n",
    "\n",
    "\n",
    "#Evaluate and store the rescaled gas prices\n",
    "rescaled_gas_prices=[min(b_fee[x]+tip[x],m_fee[x])/g_limit[x] for \\\n",
    "                    x in range(len(b_fee))]\n",
    "\n",
    "#transaction_data=transaction_data['rescaled_gas_prices']=rescaled_gas_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comparing variance*\n",
    "\n",
    "We will be comparing the variance in two ways, first, we will be simply taking the variance of the entire dataset, then we will run a simulation where the code will randomly take sets of 500 from both the pre and post EIP 1559 data and compare the variance in a simulation of many times and reports the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Clean up the data for comparison, remove outliers*\n",
    "\n",
    "I will be using the \"03_22_03_26.csv\" dataset in the CAMCOS google drive for the largest portion of data available, for both the 03_22_03_26.csv dataset and the suite spot dataset I'm going to use 40,000 results for a more appropriate comparison of variance.\n",
    "\n",
    "*First we will clean up the pre EIP dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly generate 40000 indexes for the larger dataset\n",
    "pre_index=np.random.uniform(0,len(large_pre_gas_prices)-2,40000)\n",
    "pre_index=[round(x) for x in pre_index]\n",
    "\n",
    "\n",
    "#assign values with the random indexes\n",
    "pre_gas_prices=[large_pre_gas_prices[x] for x in pre_index]\n",
    "    \n",
    "\n",
    "#gets 10% quantile and 90% quantile for both pre and post \n",
    "#for later use in removing outliers\n",
    "pre_up_lim=np.quantile(pre_gas_prices,0.9)\n",
    "pre_lo_lim=np.quantile(pre_gas_prices,0.1)\n",
    "post_up_lim=np.quantile(rescaled_gas_prices,0.9)\n",
    "post_lo_lim=np.quantile(rescaled_gas_prices,0.1)\n",
    "\n",
    "\n",
    "#Remove the outliers, save the results in two variables that\n",
    "#will be our final variables\n",
    "pre_gas=[x for x in pre_gas_prices if (x<pre_up_lim) & (x>pre_lo_lim)]\n",
    "post_gas=[x for x in rescaled_gas_prices if (x<post_up_lim) & (x>post_lo_lim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now to clean uo the suite spot data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>block_size</th>\n",
       "      <th>gas_limit</th>\n",
       "      <th>gas_used</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12475800</td>\n",
       "      <td>67620</td>\n",
       "      <td>14985280</td>\n",
       "      <td>14975121</td>\n",
       "      <td>1621574513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12475801</td>\n",
       "      <td>51571</td>\n",
       "      <td>14999911</td>\n",
       "      <td>14980854</td>\n",
       "      <td>1621574556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12475802</td>\n",
       "      <td>69401</td>\n",
       "      <td>14985264</td>\n",
       "      <td>14976410</td>\n",
       "      <td>1621574591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12475803</td>\n",
       "      <td>52812</td>\n",
       "      <td>14999897</td>\n",
       "      <td>14995444</td>\n",
       "      <td>1621574615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12475804</td>\n",
       "      <td>59044</td>\n",
       "      <td>15000000</td>\n",
       "      <td>14998997</td>\n",
       "      <td>1621574670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16097</th>\n",
       "      <td>12491295</td>\n",
       "      <td>55316</td>\n",
       "      <td>15000000</td>\n",
       "      <td>14984404</td>\n",
       "      <td>1621782641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16098</th>\n",
       "      <td>12491296</td>\n",
       "      <td>56221</td>\n",
       "      <td>14985353</td>\n",
       "      <td>14967308</td>\n",
       "      <td>1621782657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16099</th>\n",
       "      <td>12491297</td>\n",
       "      <td>47457</td>\n",
       "      <td>14999986</td>\n",
       "      <td>14972551</td>\n",
       "      <td>1621782667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16100</th>\n",
       "      <td>12491298</td>\n",
       "      <td>64960</td>\n",
       "      <td>15000000</td>\n",
       "      <td>14987757</td>\n",
       "      <td>1621782672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16101</th>\n",
       "      <td>12491299</td>\n",
       "      <td>64599</td>\n",
       "      <td>14985353</td>\n",
       "      <td>14973930</td>\n",
       "      <td>1621782689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16102 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       block_number  block_size  gas_limit  gas_used   timestamp\n",
       "0          12475800       67620   14985280  14975121  1621574513\n",
       "1          12475801       51571   14999911  14980854  1621574556\n",
       "2          12475802       69401   14985264  14976410  1621574591\n",
       "3          12475803       52812   14999897  14995444  1621574615\n",
       "4          12475804       59044   15000000  14998997  1621574670\n",
       "...             ...         ...        ...       ...         ...\n",
       "16097      12491295       55316   15000000  14984404  1621782641\n",
       "16098      12491296       56221   14985353  14967308  1621782657\n",
       "16099      12491297       47457   14999986  14972551  1621782667\n",
       "16100      12491298       64960   15000000  14987757  1621782672\n",
       "16101      12491299       64599   14985353  14973930  1621782689\n",
       "\n",
       "[16102 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get gas prices\n",
    "\n",
    "#randomly generate 40000 indexes for the larger dataset\n",
    "suite_index=np.random.uniform(0,len(large_pre_gas_prices)-2,40000)\n",
    "suite_index=[round(x) for x in pre_index]\n",
    "\n",
    "display(suite_txn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the variance in the post EIP-1559 data is 2.032898487421631e-12 and the variance in the pre EIP-1559 data is 1.8730212638091124e-24. the percentage of times the variance was lower in post EIP-1559 data durring our simulation after normalizing was 0%. Note, the data had to be normalized to make up for the discrepency of size in the units\n",
      "\n",
      " Some summary stats: \n",
      " \t Pre-EIP: \n",
      "\n",
      "\t Max: 256300001605\n",
      "\n",
      " \t Min: 108000000001\n",
      "\n",
      " \t Mean: 164944277381.53662\n",
      "\n",
      " \t Variance: 1.386410115119848e+21\n",
      "\n",
      " \t Quartile 25,50,75: 134400000383.0,158000000000.0,189000000000.0\n",
      "\n",
      " \n",
      " \t Post-EIP:\n",
      "\t Max: 2496463.8959047617\n",
      "\n",
      " \t Min: 132685.97152251133\n",
      "\n",
      " \t Mean: 617233.1705626977\n",
      "\n",
      " \t Variance: 295061619654.1383\n",
      "\n",
      " \t Quartile 25,50,75: 178221.58082857143,413566.0087105776,828456.6181150794\n",
      "\n",
      " \n",
      "\n",
      "BinomTestResult(k=164944277381, n=164944894614, alternative='greater', proportion_estimate=0.9999962579441974, pvalue=0.0)\n",
      "\n",
      " \n",
      "This result means that we reject the null hypothesis, meaning that the variance in the pre EIP framework \n",
      "is larger than the post EIP to a statistically significant degree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmcgraw/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_discrete_distns.py:75: RuntimeWarning: divide by zero encountered in _binom_sf\n",
      "  return _boost._binom_sf(k, n, p)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "        \n",
    "#######################################################################################################################\n",
    "## Simulation 1: with non-ideal data\n",
    "##\n",
    "##\n",
    "## NOTE!!! the data was of notably different scales, so in order to compare variance\n",
    "## with any sort of accuracy, we must normalize the data in our simulation\n",
    "#######################################################################################################################\n",
    "\n",
    "\n",
    "##a function to normalize the gas price data via dividing by the square of the mean\n",
    "def my_normalizer(my_list):\n",
    "    my_mean=np.mean(my_list)**2\n",
    "    return [x/my_mean for x in my_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#a function designed to take two lists, pre and post EIP respectively,\n",
    "#and return False if post is bigger and True if post is smaller\n",
    "def variance_checker(pre,post):\n",
    "    if np.var(pre)<np.var(post):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "#a function desinged to take two lists, along with a specefied integer, and then\n",
    "#generate an amount of random indexes associated with indexes to the two lists \n",
    "#in the amount of the number specified\n",
    "def random_index_generator(list1,list2,number):\n",
    "    result1=list(np.random.uniform(0,len(list1)-2,number))\n",
    "    result1=[round(x) for x in result1]\n",
    "    result2=list(np.random.uniform(0,len(list2)-2,number))\n",
    "    result2=[round(x) for x in result2]\n",
    "    return [result1,result2]\n",
    "\n",
    "\n",
    "#declare a variable to represent the number of trials to take place in the simulation \n",
    "trials=10000\n",
    "#initialize a list to represent the output of the simulation\n",
    "results=[]\n",
    "\n",
    "\n",
    "#this code runs a simulation that randomly takes 500 observations from each dataset and \n",
    "#records the percentage of times the variance is smaller in the post EIP dataset\n",
    "for i in range(trials):\n",
    "    my_index=random_index_generator(pre_gas,post_gas,500)\n",
    "    index_1=my_index[0]\n",
    "    index_2=my_index[1]\n",
    "    my_pre_gas=my_normalizer([pre_gas[x] for x in index_1])\n",
    "    my_post_gas=my_normalizer([post_gas[x] for x in index_2])\n",
    "    results.append(variance_checker(my_pre_gas,my_post_gas))\n",
    "\n",
    "    \n",
    "#output results of simulation and simple variance of the two datasets\n",
    "print(\"the variance in the post EIP-1559 data is \" +  str(np.var(my_normalizer([post_gas]))) + \\\n",
    "      \" and the variance in the pre EIP-1559 data is \" + str(np.var(my_normalizer([pre_gas]))) + \\\n",
    "      \". the percentage of times the variance was lower in post EIP-1559 data \" + \\\n",
    "      \"durring our simulation after normalizing was \" +\n",
    "      str(int(round((sum(results)/len(results))*100))) + '%. Note, the data had ' + \\\n",
    "      \"to be normalized to make up for the discrepency of size in the units\")\n",
    "\n",
    "\n",
    "#output summary stats of pre and post EIP gas prices\n",
    "print('\\n Some summary stats: \\n \\t Pre-EIP: \\n')\n",
    "print('\\t Max: ' + str(np.max(pre_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(pre_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(pre_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(pre_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(pre_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(pre_gas,0.5)) + ',' +  str(np.quantile(pre_gas,0.75)))\n",
    "print('\\n \\n \\t Post-EIP:')\n",
    "print('\\t Max: ' + str(np.max(post_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(post_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(post_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(post_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(post_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(post_gas,0.5)) + ',' +  str(np.quantile(post_gas,0.75)))\n",
    "\n",
    "\n",
    "##############################################################################################################################\n",
    "##Implimentation of the c-test\n",
    "##############################################################################################################################\n",
    "##\n",
    "##This method works by approximating the joint probability distribution of X_1 and X_2 as \n",
    "##a binomial distribution, where in the binomial distibtion, the x parameter is lambda_1 \n",
    "##(from X_1), the n parameter is lambda_1+lambda_2, and the p parameter is n_1/(n_1+n_2)\n",
    "##\n",
    "##This test finds the p-value corresponding to the ratio lambda_1/lambda_2, the reasoning\n",
    "##being that if the ratio is large, then that means lambda 1 is larger than lambda 2 (and \n",
    "##thus that variance of the pre EIP gas price is larger than the variance of the post EIP\n",
    "## gas price) to a statistically significant degree. Hence, we perform a \"greater than\" \n",
    "##binomial test to determine of the if the variance is smaller in the post EIP framework\n",
    "##\n",
    "##This method was retrieved from the following sources: \n",
    "##\n",
    "##Refference-1:https://stats.stackexchange.com/questions/109402/c-test-for-comparing-poisson-means-in-scipy\n",
    "##\n",
    "##Refference-2:https://cran.r-project.org/web/packages/rateratio.test/vignettes/rateratio.test.pdf\n",
    "##############################################################################################################################\n",
    "\n",
    "\n",
    "##grab the parameters for the test\n",
    "my_x=int(np.mean(pre_gas))\n",
    "my_n=int(np.mean(pre_gas))+int(np.mean(post_gas))\n",
    "my_p=len(pre_gas)/(len(pre_gas)+len(post_gas))\n",
    "\n",
    "\n",
    "#print the results of the test to the user\n",
    "print('\\n \\n') \n",
    "print(binomtest((my_x),my_n,my_p,alternative='greater'))\n",
    "print('\\n \\n' + 'This result means that we reject the null hypothesis, meaning that the' + \\\n",
    "      ' variance in the pre EIP framework \\n' + 'is larger than the post EIP to a ' +\\\n",
    "      'statistically significant degree' )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02cec3100af4f77b0b3609e30c0b642b32ba8aadb84a5b6ce1efd35086210958"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
