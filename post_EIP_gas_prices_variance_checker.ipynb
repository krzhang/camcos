{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import the data and the packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "from data_personal_example import transaction_data_file, block_data_file,  \\\n",
    "large_pre_gas_prices_file, suite_spot_txn, suite_spot_blx\n",
    "\n",
    "\n",
    "#Read in the data, use your own machines specific path as you see fit\n",
    "transaction_data=pd.read_csv(transaction_data_file)\n",
    "block_data=pd.read_csv(block_data_file)\n",
    "#read in the data and convert it to a list for better calculation speed\n",
    "large_pre_gas_prices=list(pd.read_csv(large_pre_gas_prices_file).gas_price)\n",
    "\n",
    "suite_txn=pd.read_csv(suite_spot_txn)\n",
    "suite_blx=pd.read_csv(suite_spot_blx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adding the gas limits into the dataframe*\n",
    "\n",
    "first we add the gas limits into the transaction dataframe, as well as add the gas limits and base fee back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the block number and gas limits and base fee from the dataset\n",
    "my_block_number=list(block_data.block_number)\n",
    "my_gas_limit=list(block_data.gas_limit)\n",
    "my_base_fee=list(block_data.base_fee_per_gas)\n",
    "#initialize a dictionary to assign gas limits and base fee to the transaction data\n",
    "gas_limit_tracker={}\n",
    "base_fee_tracker={}\n",
    "\n",
    "\n",
    "#makes a dicionary with the key being the block number and the \n",
    "#value being the gas limits and base fee, because this will allow us to \n",
    "#easily assign a gas limit and base fee to the transaction going forward\n",
    "for i in range(len(my_block_number)):\n",
    "    gas_limit_tracker[my_block_number[i]]=my_gas_limit[i]\n",
    "    base_fee_tracker[my_block_number[i]]=my_base_fee[i]\n",
    "    \n",
    "    \n",
    "##get the block numbers from the transaction data\n",
    "transaction_block_numbers=list(transaction_data.block_number)\n",
    "\n",
    "\n",
    "#initialize a list for the purpose of saving the gas limits that will \n",
    "#be assigned to the transaction data and assign the correct information\n",
    "gas_limits_for_transaction_data=[gas_limit_tracker[x] for x in transaction_block_numbers]\n",
    "base_fee_for_transaction_data=[base_fee_tracker[x] for x in transaction_block_numbers]\n",
    "\n",
    "    \n",
    "#add the column into the dataframe\n",
    "#transaction_data['gas_limit']=gas_limits_for_transaction_data\n",
    "transaction_data['base_fee']=base_fee_for_transaction_data\n",
    "\n",
    "\n",
    "# The final step is to remove the NA's from then dataframe, from testing of the \n",
    "# dataset, i have found that the max priority fee per gas and the max fee per gas\n",
    "# have the the same number of NA's -this can be oberved with the line \n",
    "# np.sum(transaction_data.isna())- that we can remove the NA's with the line...\n",
    "transaction_data=transaction_data[pd.notnull(transaction_data.max_fee_per_gas)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Rescaling the gas prices*\n",
    "\n",
    " now we need to add another column to revert the gas price into a metric that we \n",
    "can compare to the pre EIP 1559 data. to do this, we will need to work under the\n",
    " assumption that gas limits represent the same metric that they do in the pre EIP \n",
    " 1559 network (which is an assumption that the previous paper made that we will \n",
    " continue in this proposal). then, we see that the user bid has a specific value \n",
    " in the post EIP 1559 section which is min(base fee + tip , max tip), while in the pre EIP section the userbid is equal \n",
    " to gas price * gas limit. Therefore, if we set these metrics to be equal, we can \n",
    " solve for the equivilent of the gas prices in the post EIP section, giving us an ultimate answer of $\\frac{min(base \\: fee \\: + \\: tip)}{gas \\: limit}  \\: = \\: pre \\: EIP \\: gas \\: price$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the values...\n",
    "b_fee=list(transaction_data.base_fee)\n",
    "g_limit=list(transaction_data.gas)\n",
    "m_fee=list(transaction_data.max_fee_per_gas)\n",
    "tip=list(transaction_data.max_priority_fee_per_gas)\n",
    "\n",
    "\n",
    "#Evaluate and store the rescaled gas prices\n",
    "rescaled_gas_prices=[min(b_fee[x]+tip[x],m_fee[x])/g_limit[x] for \\\n",
    "                    x in range(len(b_fee))]\n",
    "\n",
    "#transaction_data=transaction_data['rescaled_gas_prices']=rescaled_gas_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comparing variance*\n",
    "\n",
    "We will be comparing the variance in two ways, first, we will be simply taking the variance of the entire dataset, then we will run a simulation where the code will randomly take sets of 500 from both the pre and post EIP 1559 data and compare the variance in a simulation of many times and reports the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Clean up the data for comparison, remove outliers*\n",
    "\n",
    "I will be using the \"03_22_03_26.csv\" dataset in the CAMCOS google drive for the largest portion of data available, for both the 03_22_03_26.csv dataset and the suite spot dataset I'm going to use 40,000 results for a more appropriate comparison of variance.\n",
    "\n",
    "*First we will clean up the pre EIP dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly generate 40000 indexes for the larger dataset\n",
    "pre_index=np.random.uniform(0,len(large_pre_gas_prices)-2,40000)\n",
    "pre_index=[round(x) for x in pre_index]\n",
    "\n",
    "\n",
    "#assign values with the random indexes\n",
    "pre_gas_prices=[large_pre_gas_prices[x] for x in pre_index]\n",
    "    \n",
    "\n",
    "#gets 10% quantile and 90% quantile for both pre and post \n",
    "#for later use in removing outliers\n",
    "pre_up_lim=np.quantile(pre_gas_prices,0.9)\n",
    "pre_lo_lim=np.quantile(pre_gas_prices,0.1)\n",
    "post_up_lim=np.quantile(rescaled_gas_prices,0.9)\n",
    "post_lo_lim=np.quantile(rescaled_gas_prices,0.1)\n",
    "\n",
    "\n",
    "#Remove the outliers, save the results in two variables that\n",
    "#will be our final variables\n",
    "pre_gas=[x for x in pre_gas_prices if (x<pre_up_lim) & (x>pre_lo_lim)]\n",
    "post_gas=[x for x in rescaled_gas_prices if (x<post_up_lim) & (x>post_lo_lim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now to clean uo the suite spot data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gas prices\n",
    "suite_gas_prices=list(suite_txn.gas_price)\n",
    "\n",
    "#randomly generate 40000 indexes for the larger dataset\n",
    "suite_index=np.random.uniform(0,len(suite_gas_prices)-2,40000)\n",
    "suite_index=[round(x) for x in suite_index]\n",
    "\n",
    "\n",
    "#assign values with the random indexes\n",
    "suite_gas_prices=[suite_gas_prices[x] for x in suite_index]\n",
    "    \n",
    "\n",
    "#gets 10% quantile and 90% quantile for both suite gas\n",
    "suite_up_lim=np.quantile(suite_gas_prices,0.9)\n",
    "suite_lo_lim=np.quantile(suite_gas_prices,0.1)\n",
    "\n",
    "\n",
    "\n",
    "#Remove the outliers, save the results\n",
    "suite_gas=[x for x in suite_gas_prices if (x<suite_up_lim) & (x>suite_lo_lim)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simulation 1: non-ideal data*\n",
    "\n",
    "This simulation will be done with a normalization method, where for each unit i in n we take $\\frac{n_i}{(n_i)^2}$ to try to account for the discrepency of the size of the units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the variance in the post EIP-1559 data is 2.032898487421631e-12 and the variance in the pre EIP-1559 data is 1.8841372148524303e-24. the percentage of times the variance was lower in post EIP-1559 data durring our simulation after normalizing was 0%. Note, the data had to be normalized to make up for the discrepency of size in the units\n",
      "\n",
      " Some summary stats: \n",
      " \t Pre-EIP: \n",
      "\n",
      "\t Max: 256500000000\n",
      "\n",
      " \t Min: 107000001561\n",
      "\n",
      " \t Mean: 165362968402.76215\n",
      "\n",
      " \t Variance: 1.4088526273866904e+21\n",
      "\n",
      " \t Quartile 25,50,75: 135000000000.0,159000000000.0,190283000000.0\n",
      "\n",
      " \n",
      " \t Post-EIP:\n",
      "\t Max: 2496463.8959047617\n",
      "\n",
      " \t Min: 132685.97152251133\n",
      "\n",
      " \t Mean: 617233.1705626977\n",
      "\n",
      " \t Variance: 295061619654.1383\n",
      "\n",
      " \t Quartile 25,50,75: 178221.58082857143,413566.0087105776,828456.6181150794\n"
     ]
    }
   ],
   "source": [
    "##a function to normalize the gas price data via dividing by the square of the mean\n",
    "def my_normalizer(my_list):\n",
    "    my_mean=np.mean(my_list)**2\n",
    "    return [x/my_mean for x in my_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#a function designed to take two lists, pre and post EIP respectively,\n",
    "#and return False if post is bigger and True if post is smaller\n",
    "def variance_checker(pre,post):\n",
    "    if np.var(pre)<np.var(post):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "#a function desinged to take two lists, along with a specefied integer, and then\n",
    "#generate an amount of random indexes associated with indexes to the two lists \n",
    "#in the amount of the number specified\n",
    "def random_index_generator(list1,list2,number):\n",
    "    result1=list(np.random.uniform(0,len(list1)-2,number))\n",
    "    result1=[round(x) for x in result1]\n",
    "    result2=list(np.random.uniform(0,len(list2)-2,number))\n",
    "    result2=[round(x) for x in result2]\n",
    "    return [result1,result2]\n",
    "\n",
    "\n",
    "#declare a variable to represent the number of trials to take place in the simulation \n",
    "trials=10000\n",
    "#initialize a list to represent the output of the simulation\n",
    "results=[]\n",
    "\n",
    "\n",
    "#this code runs a simulation that randomly takes 500 observations from each dataset and \n",
    "#records the percentage of times the variance is smaller in the post EIP dataset\n",
    "for i in range(trials):\n",
    "    my_index=random_index_generator(pre_gas,post_gas,500)\n",
    "    index_1=my_index[0]\n",
    "    index_2=my_index[1]\n",
    "    my_pre_gas=my_normalizer([pre_gas[x] for x in index_1])\n",
    "    my_post_gas=my_normalizer([post_gas[x] for x in index_2])\n",
    "    results.append(variance_checker(my_pre_gas,my_post_gas))\n",
    "\n",
    "    \n",
    "#output results of simulation and simple variance of the two datasets\n",
    "print(\"the variance in the post EIP-1559 data is \" +  str(np.var(my_normalizer([post_gas]))) + \\\n",
    "      \" and the variance in the pre EIP-1559 data is \" + str(np.var(my_normalizer([pre_gas]))) + \\\n",
    "      \". the percentage of times the variance was lower in post EIP-1559 data \" + \\\n",
    "      \"durring our simulation after normalizing was \" +\n",
    "      str(int(round((sum(results)/len(results))*100))) + '%. Note, the data had ' + \\\n",
    "      \"to be normalized to make up for the discrepency of size in the units\")\n",
    "\n",
    "\n",
    "#output summary stats of pre and post EIP gas prices\n",
    "print('\\n Some summary stats: \\n \\t Pre-EIP: \\n')\n",
    "print('\\t Max: ' + str(np.max(pre_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(pre_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(pre_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(pre_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(pre_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(pre_gas,0.5)) + ',' +  str(np.quantile(pre_gas,0.75)))\n",
    "print('\\n \\n \\t Post-EIP:')\n",
    "print('\\t Max: ' + str(np.max(post_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(post_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(post_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(post_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(post_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(post_gas,0.5)) + ',' +  str(np.quantile(post_gas,0.75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simulation 2: suite spot data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the variance in the post EIP-1559 data is 2.032898487421631e-12 and the variance in the 'suite spot' EIP-1559 data is 6.039297973124272e-23. the percentage of times the variance was lower in post EIP-1559 data durring our simulation after normalizing was 0%. Note, the data had to be normalized to make up for the discrepency of size in the units\n",
      "\n",
      " Some summary stats: \n",
      " \t Pre-EIP: (suite spot) \n",
      "\n",
      "\t Max: 227850000000\n",
      "\n",
      " \t Min: 31004000000\n",
      "\n",
      " \t Mean: 76606473800.96417\n",
      "\n",
      " \t Variance: 2.0799282164949993e+21\n",
      "\n",
      " \t Quartile 25,50,75: 44000000000.0,159000000000.0,95000000000.0\n",
      "\n",
      " \n",
      " \t Post-EIP:\n",
      "\t Max: 2496463.8959047617\n",
      "\n",
      " \t Min: 132685.97152251133\n",
      "\n",
      " \t Mean: 617233.1705626977\n",
      "\n",
      " \t Variance: 295061619654.1383\n",
      "\n",
      " \t Quartile 25,50,75: 178221.58082857143,413566.0087105776,828456.6181150794\n"
     ]
    }
   ],
   "source": [
    "#declare a variable to represent the number of trials to take place in the simulation \n",
    "trials=10000\n",
    "#initialize a list to represent the output of the simulation\n",
    "results=[]\n",
    "\n",
    "\n",
    "#this code runs a simulation that randomly takes 500 observations from each dataset and \n",
    "#records the percentage of times the variance is smaller in the post EIP dataset\n",
    "for i in range(trials):\n",
    "    my_index=random_index_generator(suite_gas,post_gas,500)\n",
    "    index_1=my_index[0]\n",
    "    index_2=my_index[1]\n",
    "    my_suite_gas=my_normalizer([suite_gas[x] for x in index_1])\n",
    "    my_post_gas=my_normalizer([post_gas[x] for x in index_2])\n",
    "    results.append(variance_checker(my_suite_gas,my_post_gas))\n",
    "\n",
    "    \n",
    "#output results of simulation and simple variance of the two datasets\n",
    "print(\"the variance in the post EIP-1559 data is \" +  str(np.var(my_normalizer([post_gas]))) + \\\n",
    "      \" and the variance in the 'suite spot' EIP-1559 data is \" + str(np.var(my_normalizer([suite_gas]))) + \\\n",
    "      \". the percentage of times the variance was lower in post EIP-1559 data \" + \\\n",
    "      \"durring our simulation after normalizing was \" +\n",
    "      str(int(round((sum(results)/len(results))*100))) + '%. Note, the data had ' + \\\n",
    "      \"to be normalized to make up for the discrepency of size in the units\")\n",
    "\n",
    "\n",
    "#output summary stats of pre and post EIP gas prices\n",
    "print('\\n Some summary stats: \\n \\t Pre-EIP: (suite spot) \\n')\n",
    "print('\\t Max: ' + str(np.max(suite_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(suite_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(suite_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(suite_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(suite_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(pre_gas,0.5)) + ',' +  str(np.quantile(suite_gas,0.75)))\n",
    "print('\\n \\n \\t Post-EIP:')\n",
    "print('\\t Max: ' + str(np.max(post_gas)))\n",
    "print('\\n \\t Min: ' + str(np.min(post_gas)))\n",
    "print('\\n \\t Mean: ' + str(np.mean(post_gas)))\n",
    "print('\\n \\t Variance: ' + str(np.var(post_gas)))\n",
    "print('\\n \\t Quartile 25,50,75: ' + str(np.quantile(post_gas,0.25)) + \",\" + \\\n",
    "      str(np.quantile(post_gas,0.5)) + ',' +  str(np.quantile(post_gas,0.75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Implementation of the c-test*\n",
    "\n",
    "This method works by approximating the joint probability distribution of X_1 and X_2 as a binomial distribution, where in the binomial distibtion, the x parameter is lambda_1 (from X_1), the n parameter is lambda_1+lambda_2, and the p parameter is n_1/(n_1+n_2) This test finds the p-value corresponding to the ratio lambda_1/lambda_2, the reasoning being that if the ratio is large, then that means lambda 1 is larger than lambda 2 (and thus that variance of the pre EIP gas price is larger than the variance of the post EIP gas price) to a statistically significant degree. Hence, we perform a \"greater than\" binomial test to determine of the if the variance is smaller in the post EIP framework.\n",
    "\n",
    "This method was retrieved from the following sources: \n",
    "\n",
    "1. https://stats.stackexchange.com/questions/109402/c-test-for-comparing-poisson-means-in-scipy\n",
    "\n",
    "2. https://cran.r-project.org/web/packages/rateratio.test/vignettes/rateratio.test.pdf\n",
    "\n",
    "*The first implementation will be conducted on the non-ideal data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "BinomTestResult(k=165362968402, n=165363585635, alternative='greater', proportion_estimate=0.9999962674188659, pvalue=0.0)\n",
      "\n",
      " \n",
      "This result means that we reject the null hypothesis, meaning that the variance in the pre EIP framework \n",
      "is larger than the post EIP to a statistically significant degree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmcgraw/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_discrete_distns.py:75: RuntimeWarning: divide by zero encountered in _binom_sf\n",
      "  return _boost._binom_sf(k, n, p)\n"
     ]
    }
   ],
   "source": [
    "##grab the parameters for the test\n",
    "my_x=int(np.mean(pre_gas))\n",
    "my_n=int(np.mean(pre_gas))+int(np.mean(post_gas))\n",
    "my_p=len(pre_gas)/(len(pre_gas)+len(post_gas))\n",
    "\n",
    "\n",
    "#print the results of the test to the user\n",
    "print('\\n \\n') \n",
    "print(binomtest((my_x),my_n,my_p,alternative='greater'))\n",
    "print('\\n \\n' + 'This result means that we reject the null hypothesis, meaning that the' + \\\n",
    "      ' variance in the pre EIP framework \\n' + 'is larger than the post EIP to a ' +\\\n",
    "      'statistically significant degree' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The second implimentation of the c-test will be on the ideal data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "BinomTestResult(k=76606473800, n=76607091033, alternative='greater', proportion_estimate=0.9999919428738034, pvalue=0.0)\n",
      "\n",
      " \n",
      "This result means that we reject the null hypothesis, meaning that the variance in the pre EIP framework (suite spot) \n",
      "is larger than the post EIP to a statistically significant degree\n"
     ]
    }
   ],
   "source": [
    "##grab the parameters for the test\n",
    "my_x=int(np.mean(suite_gas))\n",
    "my_n=int(np.mean(suite_gas))+int(np.mean(post_gas))\n",
    "my_p=len(suite_gas)/(len(suite_gas)+len(post_gas))\n",
    "\n",
    "\n",
    "#print the results of the test to the user\n",
    "print('\\n \\n') \n",
    "print(binomtest((my_x),my_n,my_p,alternative='greater'))\n",
    "print('\\n \\n' + 'This result means that we reject the null hypothesis, meaning that the' + \\\n",
    "      ' variance in the pre EIP framework (suite spot) \\n' + 'is larger than the post EIP to a ' +\\\n",
    "      'statistically significant degree' )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02cec3100af4f77b0b3609e30c0b642b32ba8aadb84a5b6ce1efd35086210958"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
